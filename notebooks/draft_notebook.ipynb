{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import pytest\n",
    "\n",
    "from rwd_analytics.cohort import CohortBuilder\n",
    "from rwd_analytics.features_selection import FeaturesSelection, time_at_risk, get_features_scores\n",
    "\n",
    "\n",
    "person = pd.DataFrame({\n",
    "    'person_id':[1, 2, 3, 4, 5],\n",
    "    'gender_concept_id':[8532, 8507, 8532, 8507, 8507],\n",
    "    'year_of_birth':[1990, 2000, 2010, 1970, 1960]\n",
    "})\n",
    "condition_occurrence = pd.DataFrame({\n",
    "    'person_id':[1, 1, 1, 1, 2, 2],\n",
    "    'condition_concept_id':[44831230, 2, 3, 4, 44831230, 2],\n",
    "    'condition_start_datetime':[\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "    ]\n",
    "})\n",
    "drug_exposure = pd.DataFrame({\n",
    "    'person_id':[1, 1, 1, 1, 2, 2],\n",
    "    'drug_concept_id':[10, 20, 30, 40, 10, 50],\n",
    "    'drug_exposure_start_datetime':[\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "    ]\n",
    "})\n",
    "observation_period = pd.DataFrame({\n",
    "    'person_id':[1, 2],\n",
    "    'observation_period_start_date':[\n",
    "        pd.to_datetime('2015-01-01'),\n",
    "        pd.to_datetime('2017-12-01')\n",
    "    ],\n",
    "    'observation_period_end_date':[\n",
    "        pd.to_datetime('2019-01-01'),\n",
    "        pd.to_datetime('2018-02-01')\n",
    "    ]\n",
    "})\n",
    "observation_period = dd.from_pandas(observation_period, npartitions=1)\n",
    "visit_occurrence = pd.DataFrame({\n",
    "    'person_id':[1],\n",
    "    'visit_start_datetime':[\n",
    "        pd.to_datetime('2017-12-10')\n",
    "    ]\n",
    "})\n",
    "visit_occurrence = dd.from_pandas(visit_occurrence, npartitions=1)\n",
    "person = dd.from_pandas(person, npartitions=1)\n",
    "condition_occurrence = dd.from_pandas(condition_occurrence, npartitions=1)\n",
    "drug_exposure = dd.from_pandas(drug_exposure, npartitions=1)\n",
    "measurement = pd.DataFrame()\n",
    "procedure = pd.DataFrame()\n",
    "measurement = dd.from_pandas(measurement, npartitions=1)\n",
    "procedure = dd.from_pandas(procedure, npartitions=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "person = pd.DataFrame({\n",
    "    'person_id':[1, 2, 3, 4, 5],\n",
    "    'gender_concept_id':[8532, 8507, 8532, 8507, 8507],\n",
    "    'year_of_birth':[1990, 2000, 2010, 1970, 1960]\n",
    "})\n",
    "condition_occurrence = pd.DataFrame({\n",
    "    'person_id':[1, 1, 1, 1, 2, 2],\n",
    "    'condition_concept_id':[44831230, 2, 3, 4, 44831230, 2],\n",
    "    'condition_start_datetime':[\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "    ]\n",
    "})\n",
    "observation_period = pd.DataFrame({\n",
    "    'person_id':[1, 2],\n",
    "    'observation_period_start_date':[\n",
    "        pd.to_datetime('2015-01-01'),\n",
    "        pd.to_datetime('2017-12-01')\n",
    "    ],\n",
    "    'observation_period_end_date':[\n",
    "        pd.to_datetime('2019-01-01'),\n",
    "        pd.to_datetime('2018-02-01')\n",
    "    ]\n",
    "})\n",
    "drug_exposure = pd.DataFrame({\n",
    "    'person_id':[1, 1, 1, 1, 2, 2],\n",
    "    'drug_concept_id':[10, 20, 30, 40, 10, 20],\n",
    "    'drug_exposure_start_datetime':[\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "    ]\n",
    "})\n",
    "\n",
    "visit_occurrence = pd.DataFrame({\n",
    "    'person_id':[1],\n",
    "    'visit_start_datetime':[\n",
    "        pd.to_datetime('2017-12-10')\n",
    "    ]\n",
    "})\n",
    "visit_occurrence = dd.from_pandas(visit_occurrence, npartitions=1).set_index('person_id')\n",
    "person = dd.from_pandas(person, npartitions=1).set_index('person_id')\n",
    "condition_occurrence = dd.from_pandas(condition_occurrence, npartitions=1).set_index('person_id')\n",
    "observation_period = dd.from_pandas(observation_period, npartitions=1).set_index('person_id')\n",
    "drug_exposure = dd.from_pandas(drug_exposure, npartitions=1).set_index('person_id')\n",
    "measurement = pd.DataFrame()\n",
    "procedure = pd.DataFrame()\n",
    "measurement = dd.from_pandas(measurement, npartitions=1)\n",
    "procedure = dd.from_pandas(procedure, npartitions=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EraCalculation():\n",
    "    def __init__(self, cohort, table, concept_ids=None):\n",
    "        \"\"\"\n",
    "        This function calculates era from first to last records.\n",
    "\n",
    "        - table is a dask dataframe: condition_occurrence, drug_exposure\n",
    "        - concept_ids is a list - if not provided, it is done on all concept_ids\n",
    "        \"\"\"\n",
    "        self.table = table\n",
    "        self.cohort = cohort\n",
    "        self.subject = self.cohort.person_id.unique().tolist()\n",
    "        self.table = self.table.loc[self.table.index.isin(self.subject)]\n",
    "        self.concept_ids = concept_ids\n",
    "\n",
    "    def __call__(self):\n",
    "        if 'condition_concept_id' in self.table.columns:\n",
    "            self.table  = self.table.rename(columns = {\n",
    "                'condition_concept_id':'concept_id',\n",
    "                'condition_start_datetime':'start_date'\n",
    "            })\n",
    "        elif 'drug_concept_id' in self.table.columns:\n",
    "            self.table  = self.table.rename(columns = {\n",
    "                'drug_concept_id':'concept_id',\n",
    "                'drug_exposure_start_datetime':'start_date'\n",
    "            })\n",
    "\n",
    "        self.table = self.table.reset_index()\n",
    "        t = self.table[['person_id', 'concept_id', 'start_date']]\n",
    "\n",
    "        if self.concept_ids is not None:\n",
    "            t = t[t['concept_id'].isin(self.concept_ids)]\n",
    "        \n",
    "        t = t.compute()\n",
    "        t['previous_start_date'] = t['start_date'].shift()\n",
    "        t['gap_time'] = (t['start_date'] - t['previous_start_date']).dt.days\n",
    "        t['previous_start_date'] = t['start_date'].shift()\n",
    "        t['gap_time'] = (t['start_date'] - t['previous_start_date']).dt.days\n",
    "        t['gap'] = t['gap_time'].apply(lambda x:1 if x > 40 else 0)\n",
    "        era = t.groupby(['person_id', 'concept_id']).agg(\n",
    "            start_date_min=pd.NamedAgg(column='start_date', aggfunc=min),\n",
    "            start_date_max=pd.NamedAgg(column='start_date', aggfunc=max),\n",
    "            count_exposure=pd.NamedAgg(column='start_date', aggfunc='count'),\n",
    "            gaps_count=pd.NamedAgg(column='gap', aggfunc=sum)\n",
    "        )\n",
    "        era['era_duration'] = (era['start_date_max'] - era['start_date_min']).dt.days\n",
    "        era = era.reset_index()\n",
    "        return era\n",
    "\n",
    "\n",
    "def era_statistics(era):\n",
    "    era = era.groupby('concept_id').agg({\n",
    "        'count':['min', 'max', 'mean', 'std'],\n",
    "        'era_duration':['min', 'max', 'mean', 'std']\n",
    "    })\n",
    "    era = round(era, 2)\n",
    "    return era"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_era_without_concept()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "What is the time for defining a gap?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>start_date_min</th>\n",
       "      <th>start_date_max</th>\n",
       "      <th>count_exposure</th>\n",
       "      <th>gaps_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_id</th>\n",
       "      <th>concept_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     start_date_min start_date_max  count_exposure  gaps_count\n",
       "person_id concept_id                                                          \n",
       "1         10             2016-01-01     2018-01-01               3           2"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "era"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Buffer dtype mismatch, expected 'Python object' but got 'long'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-1b6ccc6c1dea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m era = t.groupby(['person_id', 'concept_id']).agg({\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m'start_date'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;34m'gap'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cumsum'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m })\n\u001b[1;32m      5\u001b[0m \u001b[0mera\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'era_duration'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mera\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mera\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1453\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"aggregate\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1455\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m     \u001b[0magg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggregate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_mangle_lambdas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_aggregate\u001b[0;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m                 \u001b[0;31m# return a MI DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_any_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_new_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m_get_new_axes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m                 \u001b[0mnew_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_comb_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m_get_comb_axis\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             return _get_objs_combined_axis(\n\u001b[0;32m--> 529\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintersect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m             )\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/api.py\u001b[0m in \u001b[0;36m_get_objs_combined_axis\u001b[0;34m(objs, intersect, axis, sort)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mobs_idxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobjs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_get_axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mobs_idxes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_get_combined_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_idxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintersect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintersect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/api.py\u001b[0m in \u001b[0;36m_get_combined_index\u001b[0;34m(indexes, intersect, sort)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_union_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/api.py\u001b[0m in \u001b[0;36m_union_indexes\u001b[0;34m(indexes, sort)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mother\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"array\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36munion\u001b[0;34m(self, other, sort)\u001b[0m\n\u001b[1;32m   3216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3217\u001b[0m         uniq_tuples = lib.fast_unique_multiple(\n\u001b[0;32m-> 3218\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndarray_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndarray_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3219\u001b[0m         )\n\u001b[1;32m   3220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.fast_unique_multiple\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Buffer dtype mismatch, expected 'Python object' but got 'long'"
     ]
    }
   ],
   "source": [
    "era = t.groupby(['person_id', 'concept_id']).agg({\n",
    "    'start_date':['min', 'max', 'count'],\n",
    "    'gap':['cumsum']\n",
    "})\n",
    "era['era_duration'] = (era['max'] - era['min']).dt.days\n",
    "era = era.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>concept_id</th>\n",
       "      <th>start_date</th>\n",
       "      <th>previous_start_date</th>\n",
       "      <th>gap_time</th>\n",
       "      <th>gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>366.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>365.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_id  concept_id start_date previous_start_date  gap_time  gap\n",
       "0          1          10 2016-01-01                 NaT       NaN    0\n",
       "1          1          10 2017-01-01          2016-01-01     366.0    1\n",
       "2          1          10 2018-01-01          2017-01-01     365.0    2"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# sudo docker-compose exec --user root  notebook bash\n",
    "# pip install -U scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss, classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'age_at_index':[18, 28, 8, 48, 58],\n",
    "    'gender = female':[1, 0, 1, 0, 0],\n",
    "    'condition_1':[1, 1, 1, 0, 0],\n",
    "    'condition_2':[1, 1, 1, 0, 0],\n",
    "    'target':[0, 1, 1, 0, 0]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_features_scores(df, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X = df.iloc[:,0:4]\n",
    "scaler = StandardScaler().fit(X)\n",
    "standardized_X = scaler.transform(X)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#X = df.iloc[:,0:4]  #independent columns\n",
    "X = standardized_X\n",
    "y = df.iloc[:,-1]    #target column i.e price range\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs').fit(X, y)\n",
    "#clf.predict(X)\n",
    "proba = pd.DataFrame(clf.predict_proba(X))[[1]]\n",
    "proba.columns = ['probability']\n",
    "proba['probability'] = proba['probability'].apply(lambda x:round(x, 4))\n",
    "pd.concat([df, proba], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from rwd_analytics.lookups import Descendants, ComorbidConditions\n",
    "\n",
    "def get_features_scores(df, n_features):\n",
    "    X = df.iloc[:,0:n_features]  #independent columns\n",
    "    y = df.iloc[:,-1]    #target column i.e price range\n",
    "    \n",
    "    #apply SelectKBest class to extract top 10 best features\n",
    "    bestfeatures = SelectKBest(score_func=chi2, k=n_features)\n",
    "    fit = bestfeatures.fit(X,y)\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(X.columns)\n",
    "    \n",
    "    #concat two dataframes for better visualization \n",
    "    featureScores = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "\n",
    "    # naming the dataframe columns and rounding results\n",
    "    featureScores.columns = ['Specs', 'Score']\n",
    "    featureScores['Score'] = featureScores['Score'].round(2)\n",
    "    return featureScores.nlargest(n_features, 'Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_features_scores(df, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PredictionModels(df)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionModels():\n",
    "    def __init__(self, df):\n",
    "        a = df[df['target']==1]\n",
    "        b = df[df['target']==0]\n",
    "        print('Subjects in target=1: '+str(len(a)))\n",
    "        print('Subjects in target=0: '+str(len(b)))\n",
    "        \n",
    "        X = df.drop('target', axis=1)\n",
    "        y = df['target']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.25)\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        #if (len(a)+len(b))/20 < abs(len(b)-len(a)):\n",
    "        #    print('Imbalanced dataset: resampling train set')\n",
    "        #    print('************************************')\n",
    "        #    c = math.trunc((max(len(a), len(b)) + min(len(a), len(b)))/2)\n",
    "        #    a = self.X_train.sample(n=c, replace=True, random_state=3)\n",
    "        #    b = self.y_train.sample(n=c, replace=True, random_state=3)\n",
    "        #    df = pd.concat([a, b], ignore_index=True)\n",
    "\n",
    "    def __call__(self):\n",
    "        feedback = pd.DataFrame(columns=['Classifier', 'Model Score', 'Accuracy Score'])\n",
    "        classifiers = [\n",
    "            DummyClassifier(strategy='most_frequent', random_state=0),\n",
    "            KNeighborsClassifier(3),\n",
    "            SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
    "            #NuSVC(probability=True),\n",
    "            DecisionTreeClassifier(),\n",
    "            RandomForestClassifier(),\n",
    "            AdaBoostClassifier(),\n",
    "            GradientBoostingClassifier()\n",
    "            ]\n",
    "\n",
    "        for classifier in classifiers:\n",
    "            model = classifier.fit(self.X_train, self.y_train)\n",
    "            y_pred = model.predict(self.X_test)\n",
    "            feedback_temp = pd.DataFrame({\n",
    "                'Classifier':[classifier],\n",
    "                'Model Score':[model.score(self.X_train, self.y_train)],\n",
    "                'Accuracy Score':[accuracy_score(self.y_test, y_pred)]\n",
    "            })\n",
    "            feedback.append(feedback_temp)\n",
    "            print(classifier)\n",
    "            print(\"Training score: %.3f\" % model.score(self.X_train, self.y_train))\n",
    "            print(\"Test score: %.3f\" % accuracy_score(self.y_test, y_pred))\n",
    "            print('*** Confusion matrix ***')\n",
    "            print(confusion_matrix(self.y_test, y_pred))\n",
    "            print('*** Classification report ***')\n",
    "            print(classification_report(self.y_test, y_pred))\n",
    "            print('************************************')\n",
    "        \n",
    "        return feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
