{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pennchime.herokuapp.com/\n",
    "#https://seaborn.pydata.org/examples/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import pytest\n",
    "\n",
    "from rwd_analytics.cohort import CohortBuilder\n",
    "#from rwd_analytics.features_selection import FeaturesSelection, time_at_risk, get_features_scores\n",
    "from rwd_analytics.lookups import Descendants, Concept, ConceptRelationship, ComorbidConditions, Ingredient\n",
    "from rwd_analytics.treatment_line import last_activity_date, agg_lot_by_patient, line_generation_preprocess, LinesOfTherapy\n",
    "from rwd_analytics.predictions import get_matching_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drug_concept_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>739138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   drug_concept_id\n",
       "0           739138"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept = Concept()\n",
    "ingredient = Ingredient()\n",
    "concept_ids = concept.get_concept_id(['65862001205'])\n",
    "ingredient(pd.DataFrame({'drug_concept_id':concept.get_standard(concept_ids)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "person = pd.DataFrame({\n",
    "    'person_id':[1, 2, 3, 4, 5],\n",
    "    'gender_concept_id':[8532, 8507, 8532, 8507, 8507],\n",
    "    'year_of_birth':[1990, 2000, 2010, 1970, 1960]\n",
    "})\n",
    "condition_occurrence = pd.DataFrame({\n",
    "    'person_id':[1, 1, 1, 1, 2, 2],\n",
    "    'condition_concept_id':[44831230, 2, 3, 4, 44831230, 2],\n",
    "    'condition_start_datetime':[\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "    ]\n",
    "})\n",
    "observation_period = pd.DataFrame({\n",
    "    'person_id':[1, 2],\n",
    "    'observation_period_start_date':[\n",
    "        pd.to_datetime('2015-01-01'),\n",
    "        pd.to_datetime('2017-12-01')\n",
    "    ],\n",
    "    'observation_period_end_date':[\n",
    "        pd.to_datetime('2019-01-01'),\n",
    "        pd.to_datetime('2018-02-01')\n",
    "    ]\n",
    "})\n",
    "drug_exposure = pd.DataFrame({\n",
    "    'person_id':[1, 1, 1, 1, 2, 2],\n",
    "    'drug_concept_id':[10, 20, 30, 40, 10, 20],\n",
    "    'drug_exposure_start_datetime':[\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "    ]\n",
    "})\n",
    "\n",
    "visit_occurrence = pd.DataFrame({\n",
    "    'person_id':[1],\n",
    "    'visit_start_datetime':[\n",
    "        pd.to_datetime('2017-12-10')\n",
    "    ]\n",
    "})\n",
    "visit_occurrence = dd.from_pandas(visit_occurrence, npartitions=1).set_index('person_id')\n",
    "person = dd.from_pandas(person, npartitions=1).set_index('person_id')\n",
    "condition_occurrence = dd.from_pandas(condition_occurrence, npartitions=1).set_index('person_id')\n",
    "drug_exposure = dd.from_pandas(drug_exposure, npartitions=1).set_index('person_id')\n",
    "observation_period = dd.from_pandas(observation_period, npartitions=1).set_index('person_id')\n",
    "measurement = pd.DataFrame(columns=['person_id'])\n",
    "procedure = pd.DataFrame(columns=['person_id', 'procedure_datetime', 'procedure_concept_id'])\n",
    "measurement = dd.from_pandas(measurement, npartitions=1)\n",
    "procedure = dd.from_pandas(procedure, npartitions=1)\n",
    "omop_tables = {\n",
    "    'person':person,\n",
    "    'condition_occurrence':condition_occurrence,\n",
    "    'procedure_occurrence':procedure,\n",
    "    'drug_exposure':drug_exposure,\n",
    "    'visit_occurrence':visit_occurrence,\n",
    "    'observation_period':observation_period,\n",
    "    'measurement':measurement\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import getpass\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncts = ['NCT04083235']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your password : ········\n"
     ]
    }
   ],
   "source": [
    "\n",
    "connection = psycopg2.connect(user = \"anthony\",\n",
    "                              password = getpass.getpass('Enter your password : '),\n",
    "                              host = \"aact-db.ctti-clinicaltrials.org\",\n",
    "                              port = \"5432\",\n",
    "                              database = \"aact\")\n",
    "#ncts = [nct for nct in df['NCT Number'].unique() if pd.notnull(nct)]\n",
    "res = pd.read_sql_query(\"\"\"\n",
    "SELECT * FROM ctgov.browse_conditions WHERE nct_id IN (%s);\n",
    "\"\"\" %(','.join([\"'%s'\" % (c) for c in ncts])), con=connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>nct_id</th>\n",
       "      <th>mesh_term</th>\n",
       "      <th>downcase_mesh_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4942052</td>\n",
       "      <td>NCT04083235</td>\n",
       "      <td>Adenocarcinoma</td>\n",
       "      <td>adenocarcinoma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       nct_id       mesh_term downcase_mesh_term\n",
       "0  4942052  NCT04083235  Adenocarcinoma     adenocarcinoma"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_standard_from_mesh_name(df):\n",
    "    cols = df.columns + 'concept_id_2'\n",
    "    concept = Concept(vocabulary_id='Mesh').compute()\n",
    "    df = df.merge(concept, how='left', left_on='mesh_term', right_on='concept_name')\n",
    "    df = ConceptRelationship().get_standard(df)\n",
    "    df = df[cols]\n",
    "    df = df.rename(columns={'concept_id_2':'concept_id'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NDC                     919470\n",
       "RxNorm                  287928\n",
       "OSM                     203339\n",
       "HemOnc                    6710\n",
       "UCUM                       998\n",
       "CDM                        932\n",
       "Relationship               570\n",
       "Concept Class              380\n",
       "UB04 Typ bill              298\n",
       "PHDSC                      162\n",
       "Condition Type             118\n",
       "Vocabulary                 115\n",
       "Procedure Type              97\n",
       "Domain                      63\n",
       "UB04 Pt dis status          55\n",
       "Cost                        51\n",
       "Observation Type            29\n",
       "UB04 Point of Origin        22\n",
       "Visit Type                  18\n",
       "Drug Type                   16\n",
       "Death Type                  14\n",
       "Visit                       13\n",
       "Plan Stop Reason            13\n",
       "US Census                   13\n",
       "Meas Type                   11\n",
       "Plan                        11\n",
       "Note Type                   10\n",
       "Cost Type                    8\n",
       "Korean Revenue Code          7\n",
       "Episode                      7\n",
       "UB04 Pri Typ of Adm          6\n",
       "Sponsor                      6\n",
       "Obs Period Type              6\n",
       "Device Type                  4\n",
       "Metadata                     2\n",
       "None                         1\n",
       "Name: vocabulary_id, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept = Concept()\n",
    "concept.concept.vocabulary_id.value_counts().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleaningLabResults():\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "    \n",
    "    def test_distance_from_range(self, row, average, std):\n",
    "        if row['value_as_number']/average < 0.01:\n",
    "            if row['distance_from_range'] > row['new_distance_from_range']:\n",
    "                self.i = self.i + 1\n",
    "                return row['new_value_as_number']\n",
    "            else:\n",
    "                return row['value_as_number']\n",
    "            \n",
    "        else:\n",
    "            return row['value_as_number']\n",
    "    \n",
    "    def __call__(self):\n",
    "        measurement_dfs = []\n",
    "        for concept in self.df['measurement_concept_id'].unique().tolist():\n",
    "            df = self.df[self.df['measurement_concept_id']==concept].copy()\n",
    "            df = df[df['value_as_number']!=0]\n",
    "            std = df.value_as_number.std()\n",
    "            high = round(df[df['range_high']!=0]['range_high'].value_counts().idxmax(), 2)\n",
    "            low = round(df[df['range_low']!=0]['range_low'].value_counts().idxmax(), 2)\n",
    "            std = df[df['range_high']==high].value_as_number.std()\n",
    "            average = df[df['range_high']==high].value_as_number.mean()\n",
    "            df['range_high'] = high\n",
    "            df['range_low'] = low\n",
    "            print(std)\n",
    "            print(average)\n",
    "            print(concept)\n",
    "            print('*******')\n",
    "            \n",
    "            self.i = 1\n",
    "            while self.i != 0:\n",
    "                self.i = 0\n",
    "                df['distance_from_range'] = abs(df['value_as_number']-average)\n",
    "                df['new_value_as_number'] = df['value_as_number']*10\n",
    "                df['new_distance_from_range'] = abs(df['new_value_as_number']-average)\n",
    "                df['value_as_number'] = df.apply(self.test_distance_from_range, args=(average, std), axis=1)\n",
    "\n",
    "            self.i = 1\n",
    "            while self.i != 0:\n",
    "                self.i = 0\n",
    "                df['distance_from_range'] = abs(df['value_as_number']-average)\n",
    "                df['new_value_as_number'] = df['value_as_number']/10\n",
    "                df['new_distance_from_range'] = abs(df['new_value_as_number']-average)\n",
    "                df['value_as_number'] = df.apply(self.test_distance_from_range, args=(average, std), axis=1)\n",
    "\n",
    "            measurement_dfs.append(df)\n",
    "        measurement = pd.concat(measurement_dfs)\n",
    "        measurement = measurement.round({'value_as_number': 1, 'range_high': 1, 'range_low': 1})\n",
    "        del measurement['distance_from_range']\n",
    "        del measurement['new_value_as_number']\n",
    "        del measurement['new_distance_from_range']\n",
    "        return measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_lot(lot, cohort_enhanced, line, censoring_date):\n",
    "    lot = lot.merge(cohort_enhanced, how='left', on='person_id')\n",
    "    lot['time_to_last_activity'] = (lot['last_activity_date'] - lot['start_date']).dt.days\n",
    "    lot['time_to_next_treatment'] = (lot['end_date'] - lot['start_date']).dt.days\n",
    "    lot['event'] = lot['end_date'].apply(lambda x:0 if x > pd.to_datetime(censoring_date, format='%Y-%m-%d') else 1)\n",
    "    lot = lot[lot['event']==1]\n",
    "    lot = lot[lot['line_number']==line]\n",
    "    lot = lot.groupby('regimen_name').agg({\n",
    "        'person_id':['count'],\n",
    "        'time_to_next_treatment':['median'],\n",
    "        'time_to_last_activity':['median']\n",
    "    })\n",
    "    lot = lot[lot[('person_id', 'count')]>=50]\n",
    "    return lot.sort_values(by=[('time_to_next_treatment', 'median')], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi-squared test with similar proportions\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import chi2\n",
    "\n",
    "xi_results = pd.DataFrame({\n",
    "    'YY': [],\n",
    "    'YN': [],\n",
    "    'NY': [],\n",
    "    'NN': [],\n",
    "    'stat': [],\n",
    "    'p': [],\n",
    "    'dof': [],\n",
    "    'probability': [],\n",
    "    'interpret test-statistic': [],\n",
    "    'interpret p-value': []\n",
    "})\n",
    "table = [[16, 197], [37847, 2286732]]\n",
    "stat, p, dof, expected = chi2_contingency(table)\n",
    "prob = 0.95\n",
    "critical = chi2.ppf(prob, dof)\n",
    "\n",
    "# interpret test-statistic\n",
    "if abs(stat) >= critical:\n",
    "    test_statistic = 'Dependent (reject H0)'\n",
    "else:\n",
    "    test_statistic = 'Independent (fail to reject H0)'\n",
    "\n",
    "# interpret p-value\n",
    "alpha = 1.0 - prob\n",
    "if p <= alpha:\n",
    "    p_value = 'Dependent (reject H0)'\n",
    "else:\n",
    "    p_value = 'Independent (fail to reject H0)'\n",
    "\n",
    "# contingency table\n",
    "xi_add_results = pd.DataFrame({\n",
    "    'YY': [table[0][0]],\n",
    "    'YN': [table[0][1]],\n",
    "    'NY': [table[1][0]],\n",
    "    'NN': [table[1][1]],\n",
    "    'stat': [stat],\n",
    "    'p': [p],\n",
    "    'dof': [dof],\n",
    "    'probability':[prob],\n",
    "    'interpret test-statistic': [test_statistic],\n",
    "    'interpret p-value': [p_value]\n",
    "})\n",
    "\n",
    "xi_results = xi_results.append(xi_add_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_comorbid_conditions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_concept_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "What is the time for defining a gap?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "era"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "era = t.groupby(['person_id', 'concept_id']).agg({\n",
    "    'start_date':['min', 'max', 'count'],\n",
    "    'gap':['cumsum']\n",
    "})\n",
    "era['era_duration'] = (era['max'] - era['min']).dt.days\n",
    "era = era.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# sudo docker-compose exec --user root  notebook bash\n",
    "# pip install -U scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss, classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'age_at_index':[18, 28, 8, 48, 58],\n",
    "    'gender = female':[1, 0, 1, 0, 0],\n",
    "    'condition_1':[1, 1, 1, 0, 0],\n",
    "    'condition_2':[1, 1, 1, 0, 0],\n",
    "    'target':[0, 1, 1, 0, 0]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_features_scores(df, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X = df.iloc[:,0:4]\n",
    "scaler = StandardScaler().fit(X)\n",
    "standardized_X = scaler.transform(X)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#X = df.iloc[:,0:4]  #independent columns\n",
    "X = standardized_X\n",
    "y = df.iloc[:,-1]    #target column i.e price range\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs').fit(X, y)\n",
    "#clf.predict(X)\n",
    "proba = pd.DataFrame(clf.predict_proba(X))[[1]]\n",
    "proba.columns = ['probability']\n",
    "proba['probability'] = proba['probability'].apply(lambda x:round(x, 4))\n",
    "pd.concat([df, proba], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from rwd_analytics.lookups import Descendants, ComorbidConditions\n",
    "\n",
    "def get_features_scores(df, n_features):\n",
    "    X = df.iloc[:,0:n_features]  #independent columns\n",
    "    y = df.iloc[:,-1]    #target column i.e price range\n",
    "    \n",
    "    #apply SelectKBest class to extract top 10 best features\n",
    "    bestfeatures = SelectKBest(score_func=chi2, k=n_features)\n",
    "    fit = bestfeatures.fit(X,y)\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(X.columns)\n",
    "    \n",
    "    #concat two dataframes for better visualization \n",
    "    featureScores = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "\n",
    "    # naming the dataframe columns and rounding results\n",
    "    featureScores.columns = ['Specs', 'Score']\n",
    "    featureScores['Score'] = featureScores['Score'].round(2)\n",
    "    return featureScores.nlargest(n_features, 'Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_features_scores(df, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PredictionModels(df)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionModels():\n",
    "    def __init__(self, df):\n",
    "        a = df[df['target']==1]\n",
    "        b = df[df['target']==0]\n",
    "        print('Subjects in target=1: '+str(len(a)))\n",
    "        print('Subjects in target=0: '+str(len(b)))\n",
    "        \n",
    "        X = df.drop('target', axis=1)\n",
    "        y = df['target']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.25)\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        #if (len(a)+len(b))/20 < abs(len(b)-len(a)):\n",
    "        #    print('Imbalanced dataset: resampling train set')\n",
    "        #    print('************************************')\n",
    "        #    c = math.trunc((max(len(a), len(b)) + min(len(a), len(b)))/2)\n",
    "        #    a = self.X_train.sample(n=c, replace=True, random_state=3)\n",
    "        #    b = self.y_train.sample(n=c, replace=True, random_state=3)\n",
    "        #    df = pd.concat([a, b], ignore_index=True)\n",
    "\n",
    "    def __call__(self):\n",
    "        feedback = pd.DataFrame(columns=['Classifier', 'Model Score', 'Accuracy Score'])\n",
    "        classifiers = [\n",
    "            DummyClassifier(strategy='most_frequent', random_state=0),\n",
    "            KNeighborsClassifier(3),\n",
    "            SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
    "            #NuSVC(probability=True),\n",
    "            DecisionTreeClassifier(),\n",
    "            RandomForestClassifier(),\n",
    "            AdaBoostClassifier(),\n",
    "            GradientBoostingClassifier()\n",
    "            ]\n",
    "\n",
    "        for classifier in classifiers:\n",
    "            model = classifier.fit(self.X_train, self.y_train)\n",
    "            y_pred = model.predict(self.X_test)\n",
    "            feedback_temp = pd.DataFrame({\n",
    "                'Classifier':[classifier],\n",
    "                'Model Score':[model.score(self.X_train, self.y_train)],\n",
    "                'Accuracy Score':[accuracy_score(self.y_test, y_pred)]\n",
    "            })\n",
    "            feedback.append(feedback_temp)\n",
    "            print(classifier)\n",
    "            print(\"Training score: %.3f\" % model.score(self.X_train, self.y_train))\n",
    "            print(\"Test score: %.3f\" % accuracy_score(self.y_test, y_pred))\n",
    "            print('*** Confusion matrix ***')\n",
    "            print(confusion_matrix(self.y_test, y_pred))\n",
    "            print('*** Classification report ***')\n",
    "            print(classification_report(self.y_test, y_pred))\n",
    "            print('************************************')\n",
    "        \n",
    "        return feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
