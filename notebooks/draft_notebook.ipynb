{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pennchime.herokuapp.com/\n",
    "#https://seaborn.pydata.org/examples/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import pytest\n",
    "\n",
    "from rwd_analytics.cohort import CohortBuilder\n",
    "from rwd_analytics.features_selection import FeaturesSelection, time_at_risk, get_features_scores\n",
    "from rwd_analytics.lookups import Descendants, Concept, ConceptRelationship, ComorbidConditions, Ingredient\n",
    "from rwd_analytics.treatment_line import last_activity_date, agg_lot_by_patient, line_generation_preprocess, LinesOfTherapy\n",
    "from rwd_analytics.predictions import get_matching_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "person = pd.DataFrame({\n",
    "    'person_id':[1, 2, 3, 4, 5],\n",
    "    'gender_concept_id':[8532, 8507, 8532, 8507, 8507],\n",
    "    'year_of_birth':[1990, 2000, 2010, 1970, 1960]\n",
    "})\n",
    "condition_occurrence = pd.DataFrame({\n",
    "    'person_id':[1, 1, 1, 1, 2, 2],\n",
    "    'condition_concept_id':[44831230, 2, 3, 4, 44831230, 2],\n",
    "    'condition_start_datetime':[\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "    ]\n",
    "})\n",
    "observation_period = pd.DataFrame({\n",
    "    'person_id':[1, 2],\n",
    "    'observation_period_start_date':[\n",
    "        pd.to_datetime('2015-01-01'),\n",
    "        pd.to_datetime('2017-12-01')\n",
    "    ],\n",
    "    'observation_period_end_date':[\n",
    "        pd.to_datetime('2019-01-01'),\n",
    "        pd.to_datetime('2018-02-01')\n",
    "    ]\n",
    "})\n",
    "drug_exposure = pd.DataFrame({\n",
    "    'person_id':[1, 1, 1, 1, 2, 2],\n",
    "    'drug_concept_id':[10, 20, 30, 40, 10, 20],\n",
    "    'drug_exposure_start_datetime':[\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "        pd.to_datetime('2017-12-10'),\n",
    "    ]\n",
    "})\n",
    "\n",
    "visit_occurrence = pd.DataFrame({\n",
    "    'person_id':[1],\n",
    "    'visit_start_datetime':[\n",
    "        pd.to_datetime('2017-12-10')\n",
    "    ]\n",
    "})\n",
    "visit_occurrence = dd.from_pandas(visit_occurrence, npartitions=1).set_index('person_id')\n",
    "person = dd.from_pandas(person, npartitions=1).set_index('person_id')\n",
    "condition_occurrence = dd.from_pandas(condition_occurrence, npartitions=1).set_index('person_id')\n",
    "drug_exposure = dd.from_pandas(drug_exposure, npartitions=1).set_index('person_id')\n",
    "observation_period = dd.from_pandas(observation_period, npartitions=1).set_index('person_id')\n",
    "measurement = pd.DataFrame(columns=['person_id'])\n",
    "procedure = pd.DataFrame(columns=['person_id', 'procedure_datetime', 'procedure_concept_id'])\n",
    "measurement = dd.from_pandas(measurement, npartitions=1)\n",
    "procedure = dd.from_pandas(procedure, npartitions=1)\n",
    "omop_tables = {\n",
    "    'person':person,\n",
    "    'condition_occurrence':condition_occurrence,\n",
    "    'procedure_occurrence':procedure,\n",
    "    'drug_exposure':drug_exposure,\n",
    "    'visit_occurrence':visit_occurrence,\n",
    "    'observation_period':observation_period,\n",
    "    'measurement':measurement\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleaningLabResults():\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "    \n",
    "    def test_distance_from_range(self, row, average, std):\n",
    "        if row['value_as_number']/average < 0.01:\n",
    "            if row['distance_from_range'] > row['new_distance_from_range']:\n",
    "                self.i = self.i + 1\n",
    "                return row['new_value_as_number']\n",
    "            else:\n",
    "                return row['value_as_number']\n",
    "            \n",
    "        else:\n",
    "            return row['value_as_number']\n",
    "    \n",
    "    def __call__(self):\n",
    "        measurement_dfs = []\n",
    "        for concept in self.df['measurement_concept_id'].unique().tolist():\n",
    "            df = self.df[self.df['measurement_concept_id']==concept].copy()\n",
    "            df = df[df['value_as_number']!=0]\n",
    "            std = df.value_as_number.std()\n",
    "            high = round(df[df['range_high']!=0]['range_high'].value_counts().idxmax(), 2)\n",
    "            low = round(df[df['range_low']!=0]['range_low'].value_counts().idxmax(), 2)\n",
    "            std = df[df['range_high']==high].value_as_number.std()\n",
    "            average = df[df['range_high']==high].value_as_number.mean()\n",
    "            df['range_high'] = high\n",
    "            df['range_low'] = low\n",
    "            print(std)\n",
    "            print(average)\n",
    "            print(concept)\n",
    "            print('*******')\n",
    "            \n",
    "            self.i = 1\n",
    "            while self.i != 0:\n",
    "                self.i = 0\n",
    "                df['distance_from_range'] = abs(df['value_as_number']-average)\n",
    "                df['new_value_as_number'] = df['value_as_number']*10\n",
    "                df['new_distance_from_range'] = abs(df['new_value_as_number']-average)\n",
    "                df['value_as_number'] = df.apply(self.test_distance_from_range, args=(average, std), axis=1)\n",
    "\n",
    "            self.i = 1\n",
    "            while self.i != 0:\n",
    "                self.i = 0\n",
    "                df['distance_from_range'] = abs(df['value_as_number']-average)\n",
    "                df['new_value_as_number'] = df['value_as_number']/10\n",
    "                df['new_distance_from_range'] = abs(df['new_value_as_number']-average)\n",
    "                df['value_as_number'] = df.apply(self.test_distance_from_range, args=(average, std), axis=1)\n",
    "\n",
    "            measurement_dfs.append(df)\n",
    "        measurement = pd.concat(measurement_dfs)\n",
    "        measurement = measurement.round({'value_as_number': 1, 'range_high': 1, 'range_low': 1})\n",
    "        del measurement['distance_from_range']\n",
    "        del measurement['new_value_as_number']\n",
    "        del measurement['new_distance_from_range']\n",
    "        return measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_lot(lot, cohort_enhanced, line, censoring_date):\n",
    "    lot = lot.merge(cohort_enhanced, how='left', on='person_id')\n",
    "    lot['time_to_last_activity'] = (lot['last_activity_date'] - lot['start_date']).dt.days\n",
    "    lot['time_to_next_treatment'] = (lot['end_date'] - lot['start_date']).dt.days\n",
    "    lot['event'] = lot['end_date'].apply(lambda x:0 if x > pd.to_datetime(censoring_date, format='%Y-%m-%d') else 1)\n",
    "    lot = lot[lot['event']==1]\n",
    "    lot = lot[lot['line_number']==line]\n",
    "    lot = lot.groupby('regimen_name').agg({\n",
    "        'person_id':['count'],\n",
    "        'time_to_next_treatment':['median'],\n",
    "        'time_to_last_activity':['median']\n",
    "    })\n",
    "    lot = lot[lot[('person_id', 'count')]>=50]\n",
    "    return lot.sort_values(by=[('time_to_next_treatment', 'median')], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi-squared test with similar proportions\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import chi2\n",
    "\n",
    "xi_results = pd.DataFrame({\n",
    "    'YY': [],\n",
    "    'YN': [],\n",
    "    'NY': [],\n",
    "    'NN': [],\n",
    "    'stat': [],\n",
    "    'p': [],\n",
    "    'dof': [],\n",
    "    'probability': [],\n",
    "    'interpret test-statistic': [],\n",
    "    'interpret p-value': []\n",
    "})\n",
    "table = [[16, 197], [37847, 2286732]]\n",
    "stat, p, dof, expected = chi2_contingency(table)\n",
    "prob = 0.95\n",
    "critical = chi2.ppf(prob, dof)\n",
    "\n",
    "# interpret test-statistic\n",
    "if abs(stat) >= critical:\n",
    "    test_statistic = 'Dependent (reject H0)'\n",
    "else:\n",
    "    test_statistic = 'Independent (fail to reject H0)'\n",
    "\n",
    "# interpret p-value\n",
    "alpha = 1.0 - prob\n",
    "if p <= alpha:\n",
    "    p_value = 'Dependent (reject H0)'\n",
    "else:\n",
    "    p_value = 'Independent (fail to reject H0)'\n",
    "\n",
    "# contingency table\n",
    "xi_add_results = pd.DataFrame({\n",
    "    'YY': [table[0][0]],\n",
    "    'YN': [table[0][1]],\n",
    "    'NY': [table[1][0]],\n",
    "    'NN': [table[1][1]],\n",
    "    'stat': [stat],\n",
    "    'p': [p],\n",
    "    'dof': [dof],\n",
    "    'probability':[prob],\n",
    "    'interpret test-statistic': [test_statistic],\n",
    "    'interpret p-value': [p_value]\n",
    "})\n",
    "\n",
    "xi_results = xi_results.append(xi_add_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_comorbid_conditions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_concept_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "What is the time for defining a gap?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "era"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "era = t.groupby(['person_id', 'concept_id']).agg({\n",
    "    'start_date':['min', 'max', 'count'],\n",
    "    'gap':['cumsum']\n",
    "})\n",
    "era['era_duration'] = (era['max'] - era['min']).dt.days\n",
    "era = era.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# sudo docker-compose exec --user root  notebook bash\n",
    "# pip install -U scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss, classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'age_at_index':[18, 28, 8, 48, 58],\n",
    "    'gender = female':[1, 0, 1, 0, 0],\n",
    "    'condition_1':[1, 1, 1, 0, 0],\n",
    "    'condition_2':[1, 1, 1, 0, 0],\n",
    "    'target':[0, 1, 1, 0, 0]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_features_scores(df, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X = df.iloc[:,0:4]\n",
    "scaler = StandardScaler().fit(X)\n",
    "standardized_X = scaler.transform(X)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#X = df.iloc[:,0:4]  #independent columns\n",
    "X = standardized_X\n",
    "y = df.iloc[:,-1]    #target column i.e price range\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs').fit(X, y)\n",
    "#clf.predict(X)\n",
    "proba = pd.DataFrame(clf.predict_proba(X))[[1]]\n",
    "proba.columns = ['probability']\n",
    "proba['probability'] = proba['probability'].apply(lambda x:round(x, 4))\n",
    "pd.concat([df, proba], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from rwd_analytics.lookups import Descendants, ComorbidConditions\n",
    "\n",
    "def get_features_scores(df, n_features):\n",
    "    X = df.iloc[:,0:n_features]  #independent columns\n",
    "    y = df.iloc[:,-1]    #target column i.e price range\n",
    "    \n",
    "    #apply SelectKBest class to extract top 10 best features\n",
    "    bestfeatures = SelectKBest(score_func=chi2, k=n_features)\n",
    "    fit = bestfeatures.fit(X,y)\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(X.columns)\n",
    "    \n",
    "    #concat two dataframes for better visualization \n",
    "    featureScores = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "\n",
    "    # naming the dataframe columns and rounding results\n",
    "    featureScores.columns = ['Specs', 'Score']\n",
    "    featureScores['Score'] = featureScores['Score'].round(2)\n",
    "    return featureScores.nlargest(n_features, 'Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_features_scores(df, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PredictionModels(df)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionModels():\n",
    "    def __init__(self, df):\n",
    "        a = df[df['target']==1]\n",
    "        b = df[df['target']==0]\n",
    "        print('Subjects in target=1: '+str(len(a)))\n",
    "        print('Subjects in target=0: '+str(len(b)))\n",
    "        \n",
    "        X = df.drop('target', axis=1)\n",
    "        y = df['target']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.25)\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        #if (len(a)+len(b))/20 < abs(len(b)-len(a)):\n",
    "        #    print('Imbalanced dataset: resampling train set')\n",
    "        #    print('************************************')\n",
    "        #    c = math.trunc((max(len(a), len(b)) + min(len(a), len(b)))/2)\n",
    "        #    a = self.X_train.sample(n=c, replace=True, random_state=3)\n",
    "        #    b = self.y_train.sample(n=c, replace=True, random_state=3)\n",
    "        #    df = pd.concat([a, b], ignore_index=True)\n",
    "\n",
    "    def __call__(self):\n",
    "        feedback = pd.DataFrame(columns=['Classifier', 'Model Score', 'Accuracy Score'])\n",
    "        classifiers = [\n",
    "            DummyClassifier(strategy='most_frequent', random_state=0),\n",
    "            KNeighborsClassifier(3),\n",
    "            SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
    "            #NuSVC(probability=True),\n",
    "            DecisionTreeClassifier(),\n",
    "            RandomForestClassifier(),\n",
    "            AdaBoostClassifier(),\n",
    "            GradientBoostingClassifier()\n",
    "            ]\n",
    "\n",
    "        for classifier in classifiers:\n",
    "            model = classifier.fit(self.X_train, self.y_train)\n",
    "            y_pred = model.predict(self.X_test)\n",
    "            feedback_temp = pd.DataFrame({\n",
    "                'Classifier':[classifier],\n",
    "                'Model Score':[model.score(self.X_train, self.y_train)],\n",
    "                'Accuracy Score':[accuracy_score(self.y_test, y_pred)]\n",
    "            })\n",
    "            feedback.append(feedback_temp)\n",
    "            print(classifier)\n",
    "            print(\"Training score: %.3f\" % model.score(self.X_train, self.y_train))\n",
    "            print(\"Test score: %.3f\" % accuracy_score(self.y_test, y_pred))\n",
    "            print('*** Confusion matrix ***')\n",
    "            print(confusion_matrix(self.y_test, y_pred))\n",
    "            print('*** Classification report ***')\n",
    "            print(classification_report(self.y_test, y_pred))\n",
    "            print('************************************')\n",
    "        \n",
    "        return feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
